{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import matplotlib as plt\n",
    "import os\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Method to get the Vocab Size and normalize the score\n",
    "\n",
    "def n_vocab_size(*arg):\n",
    "    # vocab_size = np.array([])\n",
    "    # vocab_size_norm = np.array([])\n",
    "    # vocab_size = []\n",
    "    # vocab_size_norm = []\n",
    "    \n",
    "    #### Getting the Vocab Size\n",
    "    for text in arg:\n",
    "        vocab_size = np.append(vocab_size,len(set(text)))\n",
    "    \n",
    "    #### Normalizing using the formula \n",
    "    for vsize in vocab_size:\n",
    "        vocab_size_norm = np.append(vocab_size_norm,(vsize - vocab_size.min()) /\n",
    "                                                    (vocab_size.max() - vocab_size.min()))\n",
    "    \n",
    "    #### Normalizing using sklearn preprocessing \n",
    "    vocab_size_norm_sklearn = minmax_scale(vocab_size, feature_range=(0,1), axis=0)\n",
    "    \n",
    "    return(vocab_size,vocab_size_norm,vocab_size_norm_sklearn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "UnboundLocalError",
     "evalue": "local variable 'vocab_size' referenced before assignment",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-d3c18d5eda13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_vocab_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-50-8779ef566640>\u001b[0m in \u001b[0;36mn_vocab_size\u001b[1;34m(*arg)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#### Getting the Vocab Size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mvocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#### Normalizing using the formula\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'vocab_size' referenced before assignment"
     ]
    }
   ],
   "source": [
    "vocab_size = n_vocab_size(text1,text2,text3,text4,text5,text6,text7,text8,text9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "type(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[19317.  6833.  2789.  9913.  6066.  2166. 12408.  1108.  6807.]\n[1.         0.31440496 0.09231699 0.48355209 0.27228294 0.05810314\n 0.62057224 0.         0.3129771 ]\n<class 'numpy.ndarray'>\n[1.         0.31440496 0.09231699 0.48355209 0.27228294 0.05810314\n 0.62057224 0.         0.3129771 ]\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size[0])\n",
    "print(vocab_size[1])\n",
    "print(type(vocab_size[1]))\n",
    "print(vocab_size[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Normalized Values by using the formula 1.0 0.31440496457795597 0.09231698610577187 0.4835520896260091 0.2722829370091713 0.05810313581196112 0.6205722444944808 0.0 0.31297709923664124\n\n\nNormalized Values by using the formula (array([19317.,  6833.,  2789.,  9913.,  6066.,  2166., 12408.,  1108.,\n        6807.]), array([1.        , 0.31440496, 0.09231699, 0.48355209, 0.27228294,\n       0.05810314, 0.62057224, 0.        , 0.3129771 ]), array([1.        , 0.31440496, 0.09231699, 0.48355209, 0.27228294,\n       0.05810314, 0.62057224, 0.        , 0.3129771 ]))\n"
     ]
    }
   ],
   "source": [
    "#print(\"Normalized Values by using the formula\", *vocab_size[1],sep='\\n- ')\n",
    "print(\"Normalized Values by using the formula\", *vocab_size[1])\n",
    "print('\\n')\n",
    "print(\"Normalized Values by using the formula\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Normalized Values by using sklearn\n- 0.9999999999999999\n- 0.3144049645779559\n- 0.09231698610577188\n- 0.48355208962600904\n- 0.2722829370091713\n- 0.05810313581196112\n- 0.6205722444944807\n- 0.0\n- 0.3129770992366412\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalized Values by using sklearn\", *vocab_size[2],sep='\\n- ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd03e05b179a6f1b3d43dc78f183e30163ca03b692d154be2549bbe3fabbd792f43",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}