{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DS7337 NLP - HW 6\n",
    "#### David Wei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6\r\n",
    "\r\n",
    "**<u>HW 6:</u>**\r\n",
    "\r\n",
    "1.  Evaluate text similarity of Amazon book search results by doing the following:\r\n",
    "\r\n",
    "    - a. Do a book search on Amazon. Manually copy the full book title (including subtitle) of each of the top 24 books listed in the first two pages of search results. \r\n",
    "    - b. In Python, run one of the text-similarity measures covered in this course, e.g., cosine similarity. Compare each of the book titles, pairwise, to every other one. \r\n",
    "    - c. Which two titles are the most similar to each other? Which are the most dissimilar? Where do they rank, among the first 24 results?\r\n",
    "\r\n",
    "2.\tNow evaluate using a major search engine.\r\n",
    "    - a.    Enter one of the book titles from question 1a into Google, Bing, or Yahoo!. Copy the capsule of the first organic result and the 20th organic result. Take web results only (i.e., not video results), and skip sponsored results.  \r\n",
    "    - b.\tRun the same text similarity calculation that you used for question 1b on each of these capsules in comparison to the original query (book title). \r\n",
    "    - c.\tWhich one has the highest similarity measure? \r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import time\r\n",
    "import re\r\n",
    "import pandas as pd\r\n",
    "from tqdm import tqdm\r\n",
    "import random\r\n",
    "import string\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "# nltk\r\n",
    "import nltk\r\n",
    "from nltk.tokenize import RegexpTokenizer\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "from nltk.tokenize import ToktokTokenizer\r\n",
    "from nltk.tokenize import TweetTokenizer\r\n",
    "from nltk.stem import PorterStemmer\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.chunk.util import tree2conlltags,conlltags2tree\r\n",
    "\r\n",
    "# spaCy\r\n",
    "from spacy.tokenizer import Tokenizer\r\n",
    "from spacy.lang.en import English\r\n",
    "# nltk corpus\r\n",
    "from nltk.corpus import brown\r\n",
    "# POS taggers\r\n",
    "from textblob import TextBlob\r\n",
    "import spacy\r\n",
    "# viz & GUI\r\n",
    "from IPython.display import Image\r\n",
    "from IPython.core.display import HTML \r\n",
    "import matplotlib as plt\r\n",
    "# sklearn\r\n",
    "from sklearn.preprocessing import minmax_scale\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "# web scraping\r\n",
    "import requests\r\n",
    "import urllib3\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "from string import punctuation\r\n",
    "# from selenium import webdriver\r\n",
    "# from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 1**\r\n",
    "\r\n",
    "### Collecting Top 100 \"Books to Read in a Lifetime\"\r\n",
    "\r\n",
    "Source: https://amz.run/4hg5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Book: 1984 (Signet Classics), Book Cover May Vary\n",
      "# of Books: 24\n"
     ]
    }
   ],
   "source": [
    "books = ['1984 (Signet Classics), Book Cover May Vary', 'A Brief History of Time', 'A Heartbreaking Work of Staggering Genius', 'Diary of a Wimpy Kid, Book 1', 'Dune (Dune Chronicles, Book 1)', 'Fahrenheit 451', 'Me Talk Pretty One Day', ''''Middlesex: A Novel (Oprah's Book Club)''', ''''Midnight's Children: A Novel (Modern Library 100 Best Novels)''', 'The Corrections: A Novel', 'The Devil in the White City: Murder, Magic, and Madness at the Fair That Changed America', 'The Diary of a Young Girl', 'The Poisonwood Bible: A Novel', 'The Power Broker: Robert Moses and the Fall of New York', 'RIGHT STUFF', 'A Long Way Gone: Memoirs of a Boy Soldier', 'The Bad Beginning: Or, Orphans! (A Series of Unfortunate Events, Book 1)', 'A Wrinkle in Time (A Wrinkle in Time Quintet)', 'Selected Stories, 1968-1994', '''Alice's Adventures in Wonderland & Through the Looking-Glass (Bantam Classics)''', '''All the President's Men''', '''Angela's Ashes: A Memoir''', '''Are You There God? It's Me, Margaret.''', '''Bel Canto (Harper Perennial Deluxe Editions)''']\r\n",
    "print('Example Book: '+str(books[0]))\r\n",
    "print('# of Books: '+str(len(books)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing and Converting Book Titles into Vectors\r\n",
    "\r\n",
    "Steps:<br>\r\n",
    "1. We will use a TfidfVectorizer that vocabulary and idf, then returns a document-term matrix.This creates a sparse (24x110) matrix which contains all of our books (20) and the total number of unique words (92) and their occurences.<br>\r\n",
    "2. The sparse matrix is then converted into a array containing the counts and then transformed into a dataframe to better visualize our term document matrix. \r\n",
    "\r\n",
    "Source: https://studymachinelearning.com/cosine-similarity-text-similarity-metric/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 110)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "\r\n",
    "# convert list of books matrix of TF-IDF features\r\n",
    "vectorizer = TfidfVectorizer(strip_accents='ascii', lowercase=True)\r\n",
    "# fits list of book titles to return document-term matrix\r\n",
    "tfidf_matrix = vectorizer.fit_transform(books)\r\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100</th>\n",
       "      <th>1968</th>\n",
       "      <th>1984</th>\n",
       "      <th>1994</th>\n",
       "      <th>451</th>\n",
       "      <th>adventures</th>\n",
       "      <th>alice</th>\n",
       "      <th>all</th>\n",
       "      <th>america</th>\n",
       "      <th>and</th>\n",
       "      <th>...</th>\n",
       "      <th>vary</th>\n",
       "      <th>way</th>\n",
       "      <th>white</th>\n",
       "      <th>wimpy</th>\n",
       "      <th>wonderland</th>\n",
       "      <th>work</th>\n",
       "      <th>wrinkle</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1984 (Signet Classics), Book Cover May Vary</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.399772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             100  1968      1984  1994  451  \\\n",
       "1984 (Signet Classics), Book Cover May Vary  0.0   0.0  0.399772   0.0  0.0   \n",
       "\n",
       "                                             adventures  alice  all  america  \\\n",
       "1984 (Signet Classics), Book Cover May Vary         0.0    0.0  0.0      0.0   \n",
       "\n",
       "                                             and  ...      vary  way  white  \\\n",
       "1984 (Signet Classics), Book Cover May Vary  0.0  ...  0.399772  0.0    0.0   \n",
       "\n",
       "                                             wimpy  wonderland  work  wrinkle  \\\n",
       "1984 (Signet Classics), Book Cover May Vary    0.0         0.0   0.0      0.0   \n",
       "\n",
       "                                             york  you  young  \n",
       "1984 (Signet Classics), Book Cover May Vary   0.0  0.0    0.0  \n",
       "\n",
       "[1 rows x 110 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_dataframe(matrix, tokens):\r\n",
    "    # doc_names = [f'book_{i+1}' for i, _ in enumerate(matrix)]\r\n",
    "    doc_names = [books[i] for i, _ in enumerate(matrix)]\r\n",
    "    df = pd.DataFrame(data=matrix, index=doc_names, columns=tokens)\r\n",
    "    return df\r\n",
    "\r\n",
    "# convert document-term matrix to array \r\n",
    "tfidf_array = tfidf_matrix.toarray()\r\n",
    "\r\n",
    "# tokenize vectors to get the actual term (vocab) names\r\n",
    "tokens = vectorizer.get_feature_names()\r\n",
    "\r\n",
    "df = create_dataframe(tfidf_array,tokens)\r\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Linear_Kernel Distance Similarity\r\n",
    "\r\n",
    "Steps:\r\n",
    "1. Scikit-learn's version of the linear-kernel is equivalent of Cosine Similarity, only faster when the input is a sparse matrix. \r\n",
    "\r\n",
    "Source: https://scikit-learn.org/stable/modules/metrics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\r\n",
    "\r\n",
    "linear_kernel_similarity_matrix = linear_kernel(tfidf_matrix, tfidf_matrix)\r\n",
    "\r\n",
    "doc_names = [books[i] for i, _ in enumerate(linear_kernel_similarity_matrix)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Linear Kernel Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.080974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099242</td>\n",
       "      <td>0.108936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082193</td>\n",
       "      <td>0.072562</td>\n",
       "      <td>0.269569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.092528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069813</td>\n",
       "      <td>0.061633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.108936</td>\n",
       "      <td>0.092528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.106380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076633</td>\n",
       "      <td>0.154725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.080974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106380</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4    5    6         7    8   \\\n",
       "0  1.000000  0.000000  0.000000  0.099500  0.080974  0.0  0.0  0.094470  0.0   \n",
       "1  0.000000  1.000000  0.099242  0.108936  0.000000  0.0  0.0  0.000000  0.0   \n",
       "2  0.000000  0.099242  1.000000  0.092528  0.000000  0.0  0.0  0.000000  0.0   \n",
       "3  0.099500  0.108936  0.092528  1.000000  0.106380  0.0  0.0  0.124110  0.0   \n",
       "4  0.080974  0.000000  0.000000  0.106380  1.000000  0.0  0.0  0.101003  0.0   \n",
       "\n",
       "    9   ...   14        15        16        17   18        19   20   21   22  \\\n",
       "0  0.0  ...  0.0  0.000000  0.066277  0.000000  0.0  0.105806  0.0  0.0  0.0   \n",
       "1  0.0  ...  0.0  0.082193  0.072562  0.269569  0.0  0.000000  0.0  0.0  0.0   \n",
       "2  0.0  ...  0.0  0.069813  0.061633  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "3  0.0  ...  0.0  0.076633  0.154725  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "4  0.0  ...  0.0  0.000000  0.070860  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "\n",
       "    23  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_df = pd.DataFrame(linear_kernel_similarity_matrix)\r\n",
    "similarity_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Most Similar and Dissimilar Books\r\n",
    "\r\n",
    "Once the similarity matrix which is essentially a 24*24 (A*A) matrix, we will next need to do 2 things:\r\n",
    "* 1. Convert all indexes that contain similarities of themselves as NAN\r\n",
    "* 2. Create a list of NAN indexes from the flattened similarity matrix array (1d)\r\n",
    "* 3. Create a relevant sorted matrix similarity matrx without any NANs\r\n",
    "* 4. Using sorted matrix, map back to the original (24x24) matrix to get similarity Values\r\n",
    "* 5. Using similarity index and values to return the highest/lowest similarities as well as their positional rankings\r\n",
    "\r\n",
    "Source: https://stackoverflow.com/questions/54437769/how-to-rank-values-in-a-dataframe-with-indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAN Indices: [0, 25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400, 425, 450, 475, 500, 525, 550, 575]\n",
      "\n",
      "Sorted Matrix Count: 576\n",
      "Subbed Sorted Matrix Count: 552\n",
      "Subbed Count Validation: 24\n",
      "\n",
      "Highest Similarity Values: 0.37727845918634023\n",
      "Lowest Similarity Values: 0.0\n",
      "\n",
      "The Most Similar Books are: \"The Poisonwood Bible: A Novel\", \"The Corrections: A Novel\"\n",
      "The Most Similar Books Rankings Are: [12], [9]\n",
      "\n",
      "The Most Dissimlar Similar Books are: \"The Diary of a Young Girl\", \"Bel Canto (Harper Perennial Deluxe Editions)\"\n",
      "The Most Dissimlar Books Rankings Are: [11], [23]\n"
     ]
    }
   ],
   "source": [
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\r\n",
    "# pd.reset_option('all')\r\n",
    "\r\n",
    "##################### Converting self-similarity indices to NAN #####################\r\n",
    "similarity_df_stacked = similarity_df.stack() #\r\n",
    "similarity_df_stacked = similarity_df_stacked[similarity_df_stacked.index.get_level_values(0) != similarity_df_stacked.index.get_level_values(1)]\r\n",
    "similarity_matrix_flatten = similarity_df_stacked.unstack().to_numpy().flatten()\r\n",
    "similarity_matrix_sorted = similarity_matrix_flatten.argsort()\r\n",
    "\r\n",
    "##################### REMOVES NAN from Sorted Index #####################\r\n",
    "self_indexes = []\r\n",
    "for num, i in enumerate(similarity_matrix_flatten):\r\n",
    "    if np.isnan(i):\r\n",
    "        self_indexes.append(num)\r\n",
    "print(f\"NAN Indices: {self_indexes}\\n\")\r\n",
    "\r\n",
    "##################### Subbing Sorted Matrix #####################\r\n",
    "relevant_similarity_matrix = [i for i in similarity_matrix_sorted if i not in self_indexes]\r\n",
    "print(f\"Sorted Matrix Count: {len(similarity_matrix_sorted)}\")\r\n",
    "print(f\"Subbed Sorted Matrix Count: {len(relevant_similarity_matrix)}\")\r\n",
    "print(f\"Subbed Count Validation: {len(similarity_matrix_sorted) - len(relevant_similarity_matrix)}\\n\")\r\n",
    "\r\n",
    "##################### Highest and Lowest Similarity Values #####################\r\n",
    "high_similarity_index = relevant_similarity_matrix[-1]\r\n",
    "low_similarity_index = relevant_similarity_matrix[0]\r\n",
    "\r\n",
    "high_similarity_val = similarity_matrix_flatten[high_similarity_index]\r\n",
    "low_similarity_val = similarity_matrix_flatten[low_similarity_index]\r\n",
    "print(f'Highest Similarity Values: {high_similarity_val}')\r\n",
    "print(f'Lowest Similarity Values: {low_similarity_val}\\n')\r\n",
    "\r\n",
    "##################### Highest and Lowest Similarity Book Titles with Rankings #####################\r\n",
    "high_val = []\r\n",
    "for i in np.unravel_index([high_similarity_index],(24,24)):\r\n",
    "    high_val.append(i)\r\n",
    "\r\n",
    "index_a,index_b = high_val[0], high_val[1]\r\n",
    "print(f'The Most Similar Books are: \"{doc_names[int(index_a)]}\", \"{doc_names[int(index_b)]}\"')\r\n",
    "print(f'The Most Similar Books Rankings Are: {index_a}, {index_b}\\n')\r\n",
    "\r\n",
    "\r\n",
    "low_val = []\r\n",
    "for i in np.unravel_index([low_similarity_index],(24,24)):\r\n",
    "    low_val.append(i)\r\n",
    "\r\n",
    "index_a,index_b = low_val[0], low_val[1]\r\n",
    "print(f'The Most Dissimlar Similar Books are: \"{doc_names[int(index_a)]}\", \"{doc_names[int(index_b)]}\"')\r\n",
    "print(f'The Most Dissimlar Books Rankings Are: {index_a}, {index_b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2**\r\n",
    "\r\n",
    "### Search Engine Result Similarity Comparison for Top Search Result and 20th Search Result\r\n",
    "\r\n",
    "Replicating the the process for our original book list, we chose one book at random **'A Heartbreaking Work of Staggering Genius'** and using that book title, compared the similarity between the first web search result capsule and the 20th.\r\n",
    "\r\n",
    "We found that the top search result provided a 14% increase in similarity to our original book title as compared to the 20th result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result_1 = ['A Heartbreaking Work of Staggering Genius',\r\n",
    "                \"\"\"A Heartbreaking Work of Staggering Genius: Eggers, Dave ...https://www.amazon.com â€º Heartbreaking-Work-Stagg...\r\n",
    "A book that redefines both family and narrative for the twenty-first century. A Heartbreaking Work of Staggering Genius is the moving memoir of a college senior ...\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result_20 = ['A Heartbreaking Work of Staggering Genius',\r\n",
    "                \"\"\"A Heartbreaking Work Of Staggering Genius Summary ...https://www.supersummary.com â€º summary\r\n",
    "A Heartbreaking Work of Staggering Genius, a memoir by Dave Eggers (2000), was an immediate success both critically and commercially. Â· Dave's parents dieâ€‹ ...\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Search Result Similarity Matrix: \n",
      "[[1.         0.61857801]\n",
      " [0.61857801 1.        ]]\n",
      "\n",
      "20th Search Result Similarity Matrix: \n",
      "[[1.        0.5294095]\n",
      " [0.5294095 1.       ]]\n",
      "\n",
      "% Difference Between Top and 20th: 14.42%\n"
     ]
    }
   ],
   "source": [
    "#### For Top Web Result\r\n",
    "tfidf_matrix_1 = TfidfVectorizer(strip_accents='ascii', lowercase=True).fit_transform(search_result_1)\r\n",
    "linear_kernel_similarity_matrix_1 = linear_kernel(tfidf_matrix_1, tfidf_matrix_1)\r\n",
    "print(f'Top Search Result Similarity Matrix: \\n{linear_kernel_similarity_matrix_1}\\n')\r\n",
    "\r\n",
    "#### For 20th  Web Result\r\n",
    "tfidf_matrix_2 = TfidfVectorizer(strip_accents='ascii', lowercase=True).fit_transform(search_result_20)\r\n",
    "linear_kernel_similarity_matrix_2 = linear_kernel(tfidf_matrix_2, tfidf_matrix_2)\r\n",
    "print(f'20th Search Result Similarity Matrix: \\n{linear_kernel_similarity_matrix_2}\\n')\r\n",
    "\r\n",
    "### Finding % Difference ####\r\n",
    "diff = (linear_kernel_similarity_matrix_1[0][1] - linear_kernel_similarity_matrix_2[0][1])/linear_kernel_similarity_matrix_1[0][1]\r\n",
    "print(f'% Difference Between Top and 20th: {round(diff*100,2)}%')\r\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b70808bb09d2e2d464078ce99ecf7b3d3f27ec7c02200dc1c736deabdb5a3d7b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}